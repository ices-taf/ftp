1
00:00:00,030 --> 00:00:05,040
In this video we'll be looking at the
TAF workflow, which is very much centered

2
00:00:05,040 --> 00:00:10,170
on R scripts that are run sequentially.
They structure the stock assessment

3
00:00:10,170 --> 00:00:15,839
into separate steps and what we'll end up
with is clean organized and reproducible

4
00:00:15,839 --> 00:00:20,640
assessments. So the aim of TAF is to
implement a framework to organize data,

5
00:00:20,640 --> 00:00:25,230
methods, and results used in ICES
assessments, so they are easy to find and

6
00:00:25,230 --> 00:00:31,590
rerun later with new data. If you look
at the diagram showing the TAF workflow

7
00:00:31,590 --> 00:00:36,270
and the different components, it's about
going from data to analysis and results.

8
00:00:36,270 --> 00:00:42,149
We start with getting data from ICES
databases and other data sources, and

9
00:00:42,149 --> 00:00:47,640
the first step in the data folder is
to gather the data, and to filter and

10
00:00:47,640 --> 00:00:51,840
pre-process the data that will finally
be used in the assessment. So that is one

11
00:00:51,840 --> 00:00:57,600
of the major aims of TAF is to document
and script this process of preparing the

12
00:00:57,600 --> 00:01:01,140
data. Describing where they came from and
what was done to them before they were

13
00:01:01,140 --> 00:01:05,580
entered in the assessment model. Moving
on to the input folder the task there is

14
00:01:05,580 --> 00:01:11,400
to convert the data from the most
general format, crosstab year by age

15
00:01:11,400 --> 00:01:15,540
usually, into the model specific format.
So that will depend on the model: it can

16
00:01:15,540 --> 00:01:21,150
be one big text file, or an R list, or a
number of input text files, whatever the

17
00:01:21,150 --> 00:01:26,640
model will read. The model folder is
about running the model. The model

18
00:01:26,640 --> 00:01:31,799
will be coming from either a toolbox of
commonly used models or any model can be

19
00:01:31,799 --> 00:01:38,340
used within this folder. The final step,
output, is where we convert the model

20
00:01:38,340 --> 00:01:43,530
specific output into more general text
files, things like numbers of age or

21
00:01:43,530 --> 00:01:48,530
fishing mortalities, SSB, recruitment,
and so on. The final step, then, is to

22
00:01:48,530 --> 00:01:54,420
upload those results into the ICES
databases: the stock assessment graphs,

23
00:01:54,420 --> 00:01:59,729
tables and so forth. Behind each of
those folders, data, input, model, and

24
00:01:59,729 --> 00:02:05,670
output, there is an R script that governs
what takes place. So let's take a look at

25
00:02:05,670 --> 00:02:11,760
those scripts in more detail. The first
one is data.R. Again, that is where we

26
00:02:11,760 --> 00:02:15,500
pre-process the data and
write out what we call TAF data

27
00:02:15,500 --> 00:02:20,780
tables. They're very simple crosstab
text files, comma separated values.

28
00:02:20,780 --> 00:02:25,850
The next step is input.R, where we
convert those data to the model specific

29
00:02:25,850 --> 00:02:31,060
format, writing out the model input files.
In model.R we run the analysis, often

30
00:02:31,069 --> 00:02:36,650
just invoking a shell command or
an R package to run the model and

31
00:02:36,650 --> 00:02:41,870
the results will be written out as
output files. Those output files

32
00:02:41,870 --> 00:02:47,000
will often contain information about
likelihoods or gradients, and all sorts

33
00:02:47,000 --> 00:02:50,360
of extra information we don't really
need. So we extract the results of

34
00:02:50,360 --> 00:02:54,380
interest in output.R, things like
numbers at age and fishing mortalities,

35
00:02:54,380 --> 00:02:58,880
and we write them out as text files.
Other scripts that we will be working

36
00:02:58,880 --> 00:03:03,980
with are report.R, which is an
optional script where scientists can

37
00:03:03,980 --> 00:03:07,760
prepare any plots and tables that they
are going to put in the report, and

38
00:03:07,760 --> 00:03:12,530
finally there's upload.R, a very short
script describing the data that are

39
00:03:12,530 --> 00:03:17,060
uploaded into the TAF system. So what
we're going to be doing for the rest of

40
00:03:17,060 --> 00:03:23,510
the video is to go through the actual
analysis behind the 2015 ICES advice for

41
00:03:23,510 --> 00:03:28,820
North Sea spotted ray. The R scripts can
be found on GitHub. In the address you

42
00:03:28,820 --> 00:03:36,500
can see ices-taf/2015_rjm-347d and
if you want to work along while you

43
00:03:36,500 --> 00:03:41,510
watch the video, you can download these
from GitHub and work with them on your

44
00:03:41,510 --> 00:03:47,930
own computer. So let's just dive into
data.R. At the top of the script we

45
00:03:47,930 --> 00:03:53,000
have comments reminding us what is the
purpose of the script: to pre-process

46
00:03:53,000 --> 00:03:59,329
the data and to write out the TAF data
tables. In the comment we also write the

47
00:03:59,329 --> 00:04:05,420
state before the script is run and after
the script is run, in terms of the files

48
00:04:05,420 --> 00:04:12,019
and where they are. So we start with
catch.csv and surveys_all.csv on

49
00:04:12,019 --> 00:04:18,169
the TAF database, and after the script is
run we will have catch.csv, summary.csv,

50
00:04:18,169 --> 00:04:24,940
survey.csv, all found in
a new folder called data.

51
00:04:25,009 --> 00:04:33,030
We start by loading the icesTAF package
and create an empty directory. We next

52
00:04:33,030 --> 00:04:39,120
download the data, the catch and the
survey, and we start pre-processing the

53
00:04:39,120 --> 00:04:44,250
data. We select the years of interest and
the surveys of interest. We scale the

54
00:04:44,250 --> 00:04:49,490
surveys and create a combined index, as
the average of the three surveys, and

55
00:04:49,490 --> 00:04:59,699
this is the catch data. Very short
history of the catches for this

56
00:04:59,699 --> 00:05:08,539
fishery, and this is the survey data.
We have selected the years and those

57
00:05:08,539 --> 00:05:13,979
three surveys, but importantly we have
also created a combined index and that

58
00:05:13,979 --> 00:05:21,120
is the actual input data for the
assessment. We finalize the tables and we

59
00:05:21,120 --> 00:05:27,150
write them out to the data directory.
So what we have done is to create a data

60
00:05:27,150 --> 00:05:33,389
folder containing the data that will be
used in the assessment: catch.csv,

61
00:05:33,389 --> 00:05:41,460
summary.csv, and survey.csv. In the
catch.csv we have the catch history,

62
00:05:41,460 --> 00:05:48,330
in the summary we have combined the
catch history with the index that

63
00:05:48,330 --> 00:05:55,169
will be used, and the survey documents
how the index is calculated. The next

64
00:05:55,169 --> 00:06:01,289
script that is run is input.R. It is a
short script, where we will convert the

65
00:06:01,289 --> 00:06:06,389
data to model format and write out the
model input files. In other words, we will

66
00:06:06,389 --> 00:06:10,889
start with catch and survey in the data
folder, but after the script is run we

67
00:06:10,889 --> 00:06:17,550
will have input.RData in a folder
called input. So we run those commands,

68
00:06:17,550 --> 00:06:24,870
again loading the icesTAF package, creating
the directory. We simply fetch the catch

69
00:06:24,870 --> 00:06:31,560
and the survey data frames, and save
them together in one file, input.RData.

70
00:06:31,560 --> 00:06:35,370
The third script model.R runs the model

71
00:06:35,370 --> 00:06:38,770
and the results will be written out as

72
00:06:38,770 --> 00:06:46,150
dls.txt, inside the model folder.
Now it's not enough just to have

73
00:06:46,150 --> 00:06:50,980
the icesTAF package. We also fetch a
package called icesAdvice, containing the

74
00:06:50,980 --> 00:06:57,040
function that we'll be using to run the
analysis, DLS3.2. So we start by creating

75
00:06:57,040 --> 00:07:04,000
an empty folder, we get the data
from the previous step, we apply the

76
00:07:04,000 --> 00:07:14,770
DLS method 3.2, and the results are
found in the model folder as dls.txt.

77
00:07:14,770 --> 00:07:20,920
It outlines the computations behind the
advice. The advice is 291 tons, and it is

78
00:07:20,920 --> 00:07:31,030
coming from the last advice 243, and
some series of survey indices. On average

79
00:07:31,030 --> 00:07:38,290
they've been going up by 43%, and
the DLS 3.2 rule is that we're

80
00:07:38,290 --> 00:07:42,040
not going to increase the advice by
43%, but rather by maximum of 20%,

81
00:07:42,040 --> 00:07:48,060
so the advice is 291. The output.R

82
00:07:48,720 --> 00:07:54,130
script is about extracting those results
of interest and writing out the TAF

83
00:07:54,130 --> 00:07:59,350
output tables. We're going to read in the
dls.txt, and we're actually just going

84
00:07:59,350 --> 00:08:05,560
to copy it to the output folder. In more
complicated stock assessments this would

85
00:08:05,560 --> 00:08:13,020
of course take more steps, but here we
just copy between model into output.

86
00:08:13,020 --> 00:08:20,680
Finally, in the report.R, we're going
to prepare plots and tables that could

87
00:08:20,680 --> 00:08:24,729
be included in the stock assessment
report. Taking the summary from the data

88
00:08:24,729 --> 00:08:33,940
step, we're just going to be plotting
the survey as a PNG file. So we load the

89
00:08:33,940 --> 00:08:39,849
icesTAF package, we create an empty
directory report, we read in the summary,

90
00:08:39,849 --> 00:08:43,409
and we

91
00:08:44,540 --> 00:08:52,520
create the plot, and we also write out
the summary table, but this time rounding

92
00:08:52,520 --> 00:08:59,280
the catch and the index values, to make it
look better in a report. Inside the

93
00:08:59,280 --> 00:09:06,360
report folder, we now have summary.csv
and survey.png. The survey looks simple

94
00:09:06,360 --> 00:09:11,850
enough, ready to be pasted into the
report, and the summary rounds the

95
00:09:11,850 --> 00:09:21,030
indices, so that they will look better in
a report, maybe with three decimals or so.

96
00:09:21,030 --> 00:09:27,810
So you would just copy this into the
report, essentially. In the R scripts we've

97
00:09:27,810 --> 00:09:32,610
been using some commands that are
outside of base R. We've been using

98
00:09:32,610 --> 00:09:40,170
some ICES packages. So let's take a look
at, for example, DLS3.2. The help page

99
00:09:40,170 --> 00:09:46,500
describes it as a function to apply
ICES method 3.2, and it has some good

100
00:09:46,500 --> 00:09:51,750
guidelines and references on how to use
that function. We've also been using

101
00:09:51,750 --> 00:09:57,750
some R functions from the icesTAF
package. If we just take a look at

102
00:09:57,750 --> 00:10:04,440
the main help page for the icesTAF
package, it lists all the functions by

103
00:10:04,440 --> 00:10:09,000
their groups. So some of them
we've been using to read and write

104
00:10:09,000 --> 00:10:21,150
files, we've been using cp and mkdir
to manipulate files. We used tafpng

105
00:10:21,150 --> 00:10:29,450
to open a PNG graphics device, to draw
an image and write it in PNG format.

106
00:10:29,450 --> 00:10:34,590
Most of the icesTAF functions are very
short and simple, but they're simply

107
00:10:34,590 --> 00:10:40,410
there to make the scripts look
more readable. They're convenient

108
00:10:40,410 --> 00:10:45,600
shorthand functions, to get to the point
without some boilerplate code that is

109
00:10:45,600 --> 00:10:53,520
needed. For example, in the report.R
we were using tafpng like that, so it

110
00:10:53,520 --> 00:11:00,390
uses the suggested image size and
so forth. We also see in the help page

111
00:11:00,390 --> 00:11:08,730
some functions that we will now take a
look at, to run the scripts. There are

112
00:11:08,730 --> 00:11:13,740
convenient functions for that as well:
sourceTAF is to run a single script

113
00:11:13,740 --> 00:11:18,810
and sourceAll is to run all of them.
So let's take a look at how we can use

114
00:11:18,810 --> 00:11:25,380
those, instead of running line by line
like we were doing. We can start from

115
00:11:25,380 --> 00:11:35,790
scratch with nothing in here. We can
run them one by one: sourceTAF data.R.

116
00:11:35,790 --> 00:11:44,640
Very similar to the base R function
to source. It adds some sort of

117
00:11:44,640 --> 00:11:49,800
helpful message, with the time and what
it's doing. But more importantly, we can

118
00:11:49,800 --> 00:11:56,700
run all of them: sourceAll. They run
blazing fast, it's data.R, input.R,

119
00:11:56,700 --> 00:12:01,220
model.R, output.R, and
report.R. That is how

120
00:12:01,220 --> 00:12:07,200
assessment will be run on TAF once
they're uploaded, using sourceAll.

121
00:12:07,200 --> 00:12:12,660
So what we have learned in this video is
about the overall TAF workflow. We used

122
00:12:12,660 --> 00:12:20,070
as an example the North Sea spotted ray,
as a fully scripted analysis. We also

123
00:12:20,070 --> 00:12:27,090
have on the GitHub TAF page other
examples that can be studied in the

124
00:12:27,090 --> 00:12:33,270
same way. That is Icelandic haddock, North
Sea cod, and Eastern Channel plaice. They

125
00:12:33,270 --> 00:12:39,840
are all age based assessments. The Eastern
Channel plaice uses the FLR suite of

126
00:12:39,840 --> 00:12:44,820
R packages, and the North Sea cod is a
SAM model. The Icelandic haddock is an

127
00:12:44,820 --> 00:12:51,500
AD Model Builder age based model, and we'll
be adding more examples there as we go.

128
00:12:51,500 --> 00:12:57,300
In a future video, we will be covering
the TAF web interface, where assessments

129
00:12:57,300 --> 00:13:02,850
can be browsed, run, and modified, and
how web services can be used to upload,

130
00:13:02,850 --> 00:13:06,380
download, and run models.
